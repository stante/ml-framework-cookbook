{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets which are available in the framework\n",
    "## Problem\n",
    "You want to load a dataset (e.g., MNIST) which is available directly in the framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution in TensorFlow\n",
    "\n",
    "The datasets are available in TensorFlow via the `tensorflow.keras.datasets` module. Within that module, multiple submodules exist for each dataset. With TensorFlow 2.0 and 1.4, the following dataset modules are available: \n",
    "\n",
    "* Boston housing price regression dataset (`boston_housing`).\n",
    "* CIFAR10 small images classification dataset (`cifar10`).\n",
    "* CIFAR100 small images classification dataset (`cifar100`).\n",
    "* Fashion-MNIST dataset (`fashion_mnist`).\n",
    "* IMDB sentiment classification dataset (`imdb`).\n",
    "* MNIST handwritten digits dataset (`mnist`).\n",
    "* Reuters topic classification dataset (`reuters`).\n",
    "\n",
    "The method `load_data()` returns two tuples for test and training datasets, each with data and labels. Depending on the dataset, the method can have different arguments, for example, `test_split` for splitting the fraction of the test and training set in the Boston housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets as datasets\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution in PyTorch\n",
    "\n",
    "PyTorch comes with an optional `torchvision` package which contains only image related datasets. Access the dataset with a `Dataset` class (e.g., `MNIST`) and the `DataLoader` class. The `Dataset` class is used to determine which dataset is used (including the separation of test and training set) and what transformations to perform. The `DataLoader` represents an iterator and therefore allows to configure the batch size and the sampling strategy of the dataset. The `torchvision` package comes with an extensive list of datasets, in the `torchvision.datasets` package. The following dataset classes are available:\n",
    "\n",
    "* MNIST dataset of handwritten digits (`MNIST`).\n",
    "* Fashion-MNIST dataset (`FashionMNIST`).\n",
    "* Kuzushiji-MNIST dataset of handwritten japanese characters (`KMNIST`).\n",
    "* Extension of MNIST dataset to handwritten letters (`EMNIST`).\n",
    "* Recreation of the MNIST dataset (`QMNIST`).\n",
    "* COCO captions dataset (`CocoCaptions`).\n",
    "* COCO detection dataset (`CocoDetection`).\n",
    "* Large scale image understanding dataset (`LSUN`).\n",
    "* ImageNet 2012 classification dataset (`ImageNet`).\n",
    "* CIFAR10 small images classification dataset (`CIFAR10`).\n",
    "* CIFAR100 small images classification dataset (`CIFAR100`).\n",
    "* STL10 small images for unsupervised feature learning dataset (`STL10`)\n",
    "* Street View Hause Number dataset (`SVHN`).\n",
    "* PhotoTour dataset (`PhotoTour`).\n",
    "* SBU captions dataset (`SBU`).\n",
    "* Flickr8k captions dataset (`Flickr8k`).\n",
    "* Flickr30k captions dataset (`Flick30k`).\n",
    "* Pascal VOC segmentation dataset (`VOCSegmentation`).\n",
    "* Pascal VOC detection dataset (`VOCDetection`).\n",
    "* Cityscapes segmentation dataset (`Cityscapes`).\n",
    "* SBD semantic contours dataset (`SBDataset`).\n",
    "* USPS handwritten text dataset (`USPS`).\n",
    "* Kinetics-400 action recognition videos dataset (`Kinetics400`).\n",
    "* HMDB51 action recognition videos dataset (`HMDB51`).\n",
    "* UCF101 action recognition videos dataset (`UCF101`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "dataset = datasets.MNIST(root='~/.torch/MNIST', train=True, transform=transforms.ToTensor())\n",
    "dataloader = data.DataLoader(dataset)\n",
    "\n",
    "for train_x, train_y in dataloader:\n",
    "    # Training loop\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train` argument selects the training set (set to `True`) or test set (set to `False`). The `transform` argument specifies what transformations to apply to the dataset. In this example, it only transforms an image into a tensor. However, more complex transformation chains can be defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Boston housing, IMDB and Reuters datasets, TensorFlow offers more variety compared to the image only related datasets in PyTorch. A significant difference between TensorFlow and PyTorch is that TensorFlow provides a training loop via the model's `fit` method and in PyTorch, the user has to write it himself and therefore needs an iterator (`DataLoader`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
